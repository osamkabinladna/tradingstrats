{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-02T10:18:00.839836Z",
     "start_time": "2024-09-02T10:18:00.804571Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from utils import split_dataset"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T10:18:02.586963Z",
     "start_time": "2024-09-02T10:18:01.116294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load covariates and convert index to datetime\n",
    "covariates = pd.read_csv(\"./data/bdataaug.csv\", index_col=\"Dates\", skiprows=5)\n",
    "covariates.index = pd.to_datetime(covariates.index)\n",
    "\n",
    "# Load labels and convert index to datetime\n",
    "labels = pd.read_csv(\"./data/jkse.csv\", skiprows=0, index_col='Date')\n",
    "labels.index = pd.to_datetime(labels.index)\n",
    "\n",
    "# Rename column and calculate percentage change\n",
    "labels = labels.rename(columns={\"Close\": \"JKSE_PRICE\"})\n",
    "labels['PCT_CHANGE_20_JKSE'] = ((labels['JKSE_PRICE'].shift(-20) - labels['JKSE_PRICE']) / labels['JKSE_PRICE']) * 100\n",
    "\n",
    "# Format the index to the desired format\n",
    "covariates.index = covariates.index.strftime('%d-%B-%Y')\n",
    "labels.index = labels.index.strftime('%d-%B-%Y')"
   ],
   "id": "334f7778c2fc2498",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Split the dataset per ticker",
   "id": "13d54e52cd936517"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T09:39:51.345995Z",
     "start_time": "2024-09-02T09:39:51.238765Z"
    }
   },
   "cell_type": "code",
   "source": "covlist = split_dataset(covariates)",
   "id": "f7ebe0c42c883e40",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Create technical covariates\n",
    "\n",
    "\n",
    "### PE Band & P/E Ratio  \n",
    "$$\n",
    " \\text{P/E Ratio} = \\frac{1}{\\text{EARN\\_YLD}} \n",
    "$$\n",
    "\n",
    "* $PE Band_q $ is the q-th percentile of P/E Ratio in a 60 trading days rolling window\n",
    "\n",
    "### Mean Average Convergence/Divergence (MACD)\n",
    "\n",
    "- MACD is the difference of short term $\\text{EMA}_{12}$ and long term $\\text{EMA}_{26}$ (signal for momentum)\n",
    "- MACD Signal is the signal line of 9 day EMA of the MACD\n",
    "- MACD Histogram is the difference between the MACD line and the signal line"
   ],
   "id": "31cc71b24c87fad5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T09:42:17.032828Z",
     "start_time": "2024-09-02T09:42:13.885766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "colnames = covlist[0].columns.tolist()\n",
    "for cov in covlist:\n",
    "    # unify column names\n",
    "    cov.columns = colnames\n",
    "for cov in covlist:\n",
    "    # Volume = Turnover / Close Price\n",
    "    cov['VOLUME'] = cov['TURNOVER'] / cov['PX_LAST']\n",
    "    # Calculate percent change * 100\n",
    "    cov['PCT_CHANGE_20'] = ((cov['PX_LAST'].shift(-20) - cov['PX_LAST']) / cov['PX_LAST']) * 100\n",
    "    # Ratio 10/30 = mean volume ratio for the last 10 days / mean volume ratio for the last 30 days\n",
    "    cov['VOL_RATIO_10_20'] = cov['VOLUME'].rolling(window=10).mean() / cov['VOLUME'].rolling(window=20).mean()\n",
    "    cov['VOL_RATIO_20_40'] = cov['VOLUME'].rolling(window=20).mean() / cov['VOLUME'].rolling(window=40).mean()\n",
    "    cov['VOL_RATIO_40_80'] = cov['VOLUME'].rolling(window=40).mean() / cov['VOLUME'].rolling(window=80).mean()\n",
    "    cov['VOL_RATIO_80_120'] = cov['VOLUME'].rolling(window=80).mean() / cov['VOLUME'].rolling(window=120).mean()\n",
    "    \n",
    "    # PE Band\n",
    "    cov['PE_Ratio'] = 1 / cov['EARN_YLD']\n",
    "    win = 60  # Set the rolling window period\n",
    "    cov['PE_Band_25'] = cov['PE_Ratio'].rolling(win).quantile(0.25)\n",
    "    cov['PE_Band_50'] = cov['PE_Ratio'].rolling(win).quantile(0.50)\n",
    "    cov['PE_Band_75'] = cov['PE_Ratio'].rolling(win).quantile(0.75)\n",
    "\n",
    "    # Calculate the 12-day EMA of PX_LAST\n",
    "    ema_12 = cov['PX_LAST'].ewm(span=12, adjust=False).mean()\n",
    "\n",
    "    # Calculate the 26-day EMA of PX_LAST\n",
    "    ema_26 = cov['PX_LAST'].ewm(span=26, adjust=False).mean()\n",
    "\n",
    "    # Calculate MACD\n",
    "    cov['MACD'] = ema_12 - ema_26\n",
    "\n",
    "    # Calculate the Signal line (9-day EMA of MACD)\n",
    "    cov['MACD_Signal'] = cov['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "    # Optionally, you can also calculate the MACD Histogram (the difference between MACD and Signal line)\n",
    "    cov['MACD_Histogram'] = cov['MACD'] - cov['MACD_Signal']\n",
    "    \n",
    "    # Example: Momentum Indicator for various lags\n",
    "    lags = [10, 20, 30, 60, 120]\n",
    "    for lag in lags:\n",
    "        cov[f'MOMENTUM_{lag}'] = cov['PX_LAST'] / cov['PX_LAST'].shift(lag)\n",
    "        cov[f'TURNOVER_{lag}'] = cov['TURNOVER'].rolling(window=lag).mean()\n",
    "        cov[f'PX_MOMENTUM_{lag}'] = cov['PX_LAST'] / cov['PX_LAST'].shift(lag)\n",
    "        cov[f'PX_REVERSAL_{lag}'] = cov['PX_LAST'].shift(lag) / cov['PX_LAST']\n",
    "        cov[f'VOLATILITY_{lag}'] = cov['PX_LAST'].rolling(window=lag).std()\n",
    "        cov[f'VOLUME_STD_{lag}'] = cov['VOLUME'].rolling(window=lag).std()"
   ],
   "id": "708a78eee2041e04",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Remove duplicate indices if any\n",
    "labels = labels[~labels.index.duplicated(keep='first')]\n",
    "\n",
    "for i in range(len(covlist)):\n",
    "    cov = covlist[i]\n",
    "    cov = cov[~cov.index.duplicated(keep='first')]\n",
    "\n",
    "    # Explicitly create a copy of the cov DataFrame to avoid SettingWithCopyWarning\n",
    "    cov_copy = cov.copy()\n",
    "\n",
    "    # Align the DataFrames on their indices (dates)\n",
    "    aligned_df = labels.join(cov_copy[['PCT_CHANGE_20']], how='inner')\n",
    "\n",
    "    # Calculate the difference and store it in cov_copy DataFrame\n",
    "    cov_copy.loc[aligned_df.index, 'DELTA_20_CHANGE'] = aligned_df['PCT_CHANGE_20'] - aligned_df['PCT_CHANGE_20_JKSE']\n",
    "\n",
    "    # Update the original DataFrame in covlist\n",
    "    covlist[i] = cov_copy\n"
   ],
   "id": "f39a56e0fd21c2e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tickernames = [col[:4] for col in pd.read_csv(\"./data/bdataaug.csv\", skiprows=3).columns if not col.startswith(\"Unnamed\")]",
   "id": "dc8b53847dbb8f14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(len(covlist)):\n",
    "    covlist[i]['Ticker'] = tickernames[i]"
   ],
   "id": "64c3ecbe463ade09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "covlist[0]",
   "id": "f0dee6f9aaf8dca3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def unique_index(df, suffix):\n",
    "    df_copy = df.copy()\n",
    "    new_index = [f\"{date.strftime('%d-%B-%Y')}-{suffix}\" for date in df.index]\n",
    "    df_copy.index = new_index\n",
    "    return df_copy"
   ],
   "id": "836782ff8afe9e38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create reindexed covlist + pool to find quantiles + insert index back to other covariates",
   "id": "b281f02f70d3c1d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "covlist_reindex = []\n",
    "for idx, cov in enumerate(covlist):\n",
    "    cov['Ticker'] = cov['Ticker'].unique()[0]\n",
    "    covlist_reindex.append(unique_index(cov, idx))\n",
    "    \n",
    "pooled_df = pd.DataFrame()\n",
    "for i, df in enumerate(covlist_reindex):\n",
    "    pooled_df = pd.concat([pooled_df, df['DELTA_20_CHANGE']])\n",
    "\n",
    "pooled_df['DELTA_20_QUINTILES'] = pd.qcut(pooled_df[0], q=10, labels=range(1, 11))\n",
    "\n",
    "for i, df in enumerate(covlist_reindex):\n",
    "    df['DELTA_20_QUINTILES'] = pooled_df.loc[df.index, 'DELTA_20_QUINTILES']\n",
    "    covlist_reindex[i] = df"
   ],
   "id": "de2395e9ef3897a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for cov in covlist_reindex:\n",
    "    cov['TOP_5'] = cov['DELTA_20_QUINTILES'].apply(lambda x: 1 if x in [8, 9, 10] else 0)"
   ],
   "id": "18a008d2e58efef4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "covlist_reindex[1]['Ticker']",
   "id": "9a95da2b8ce2c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- covlist reindex of length 342\n",
   "id": "9039e16861a30871"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "def rolling_window_label(covlist_reindex, train_window=252, test_window=60):\n",
    "    labeled_dfs = []\n",
    "\n",
    "    for cov in covlist_reindex:\n",
    "        # Create new columns to label the data\n",
    "        cov['set'] = 'None'\n",
    "        cov['window'] = 0\n",
    "\n",
    "        # Iterate over the DataFrame with a rolling window approach in reverse order\n",
    "        window_num = 1\n",
    "        for start in range(len(cov) - test_window - train_window, -1, -test_window):\n",
    "            end_valid = start + test_window\n",
    "            end_train = end_valid + train_window\n",
    "\n",
    "            # Label the validation period\n",
    "            cov.loc[start:end_valid, 'set'] = 'Validation'\n",
    "            cov.loc[start:end_valid, 'window'] = window_num\n",
    "\n",
    "            # Label the training period\n",
    "            cov.loc[end_valid:end_train, 'set'] = 'Training'\n",
    "            cov.loc[end_valid:end_train, 'window'] = window_num\n",
    "\n",
    "            window_num += 1\n",
    "\n",
    "        labeled_dfs.append(cov)\n",
    "\n",
    "    return labeled_dfs\n",
    "\n",
    "# Example usage with the adapted function\n",
    "labeled_covlist = rolling_window_label(covlist_reindex, 252, 60)\n",
    "labeled_covlist[0].head()  # Display the head of the first labeled DataFrame for inspection"
   ],
   "id": "2927a9f2b3d803da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(len(covlist_reindex)):\n",
    "    covlist_reindex[i] = covlist_reindex[i].dropna(axis=0, how='any')\n",
    "    covlist_reindex[i] = covlist_reindex[i].reset_index(drop=False)"
   ],
   "id": "cc85e2c6ddcc3cae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "save data",
   "id": "6f210af4c10b59df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "def rolling_window_label(covlist_reindex, train_window=252, test_window=60):\n",
    "    labeled_dfs = []\n",
    "\n",
    "    for cov in covlist_reindex:\n",
    "        # Create new columns to label the data\n",
    "        cov['set'] = 'None'\n",
    "        cov['window'] = 0\n",
    "\n",
    "        # Iterate over the DataFrame with a rolling window approach in reverse order\n",
    "        window_num = 1\n",
    "        for start in range(len(cov) - test_window - train_window, -1, -test_window):\n",
    "            end_valid = start + test_window\n",
    "            end_train = end_valid + train_window\n",
    "\n",
    "            # Label the validation period\n",
    "            cov.iloc[start:end_valid, cov.columns.get_loc('set')] = 'Validation'\n",
    "            cov.iloc[start:end_valid, cov.columns.get_loc('window')] = window_num\n",
    "\n",
    "            # Label the training period\n",
    "            cov.iloc[end_valid:end_train, cov.columns.get_loc('set')] = 'Training'\n",
    "            cov.iloc[end_valid:end_train, cov.columns.get_loc('window')] = window_num\n",
    "\n",
    "            window_num += 1\n",
    "\n",
    "        labeled_dfs.append(cov)\n",
    "\n",
    "    return labeled_dfs\n",
    "\n",
    "# Example usage with the adapted function\n",
    "# Replace 'your_data' with your actual DataFrame list\n",
    "labeled_covlist = rolling_window_label([covlist_reindex], 252, 60)\n",
    "print(labeled_covlist[0].head())  # Display the head of the first labeled DataFrame for inspection"
   ],
   "id": "22acc909ad3bccbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6ca530990aa4c77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a56f45e05c3cee57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "labeled_covlist[0]",
   "id": "7ee6a91102860f53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def rolling_window_save(covlist_reindex, train_window=252, test_window=40, valid=False):\n",
    "    tdf = []\n",
    "    vdf = []\n",
    "\n",
    "    for cov in covlist_reindex:\n",
    "        # Remove specific columns and reset the index but keep the original one\n",
    "        # cov = cov.drop(['DELTA_20_CHANGE'], axis=1) if valid else cov.drop(['DELTA_20_CHANGE', 'PCT_CHANGE_20'], axis=1)\n",
    "\n",
    "        # Iterate over the DataFrame with a rolling window approach\n",
    "        for start in range(0, len(cov) - train_window - test_window + 1, test_window):\n",
    "            end_train = start + train_window\n",
    "            end_test = end_train + test_window\n",
    "\n",
    "            train_df = cov.iloc[start:end_train].reset_index(drop=False)\n",
    "            test_df = cov.iloc[end_train:end_test].reset_index(drop=False)\n",
    "\n",
    "            tdf.append(train_df)\n",
    "            vdf.append(test_df)\n",
    "\n",
    "    return tdf, vdf\n",
    "\n",
    "# Example usage\n",
    "tdf, vdf = rolling_window_save(covlist_reindex, 252, 60)"
   ],
   "id": "b4880f2292fc3687",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(covlist_reindex)",
   "id": "2055bfb929bb463f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "covlist_reindex[4]",
   "id": "d20ec2820aa4c742",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for idx, vdfe in enumerate(covlist_reindex):\n",
    "    i = 0\n",
    "    if len(vdfe) != 0:\n",
    "        print(idx, vdfe.loc[1, \"Ticker\"])\n",
    "    else:\n",
    "        i += 1\n",
    "print(f\"missing {i} tickers\")"
   ],
   "id": "e7b4bc8fb175c9dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(vdf)",
   "id": "309fec8ac1d2446f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for v in vdf:\n",
    "    v.index = v['index']\n",
    "    v.drop(['level_0', 'index', 'DELTA_20_CHANGE'], axis=1, inplace=True)"
   ],
   "id": "3e7e86ef9732e1d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for t in tdf:\n",
    "    t.index = t['index']\n",
    "    t.drop(['level_0', 'index', 'DELTA_20_CHANGE', 'PCT_CHANGE_20'], axis=1, inplace=True)"
   ],
   "id": "c941b52adc4de71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train = pd.concat(tdf, axis=0)\n",
    "valid = pd.concat(vdf, axis=0)"
   ],
   "id": "61b6a992cf348c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_valid = valid.drop(['PCT_CHANGE_20', 'DELTA_20_QUINTILES', 'Ticker', 'TOP_5'], axis=1)\n",
    "y_valid = valid[['TOP_5']]"
   ],
   "id": "da31a48025cf2dfe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_train = train.drop(['DELTA_20_QUINTILES', 'Ticker', 'TOP_5'], axis=1)\n",
    "y_train = train[['TOP_5']]"
   ],
   "id": "82de9dd4e75d906",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(x_valid, './models/yuge70_xvalid.joblib')\n",
    "joblib.dump(y_valid, './models/yuge70_yvalid.joblib')\n",
    "joblib.dump(valid, './models/yuge70_validfull.joblib')"
   ],
   "id": "f3077c6ee5b9171a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_valid.to_csv('./data/yuge70_xvalid.csv', index=True)\n",
    "y_valid.to_csv('./data/yuge70_yvalid.csv', index=True)\n",
    "x_train.to_csv('./data/yuge70_xtrain.csv', index=True)\n",
    "y_train.to_csv('./data/yuge70_ytrain.csv', index=True)\n"
   ],
   "id": "2f55684e520fc6e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "valid = pd.concat(, axis=0)\n",
    "valid.index = valid['index']\n",
    "valid.drop('index', axis=1, inplace=True)"
   ],
   "id": "92155e4e953a6423",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "valid.loc[:, ['PX_LAST', \"VOLATILITY_20\", 'Ticker', 'DELTA_20_CHANGE', \"DELTA_20_QUINTILES\", \"TOP_5\", \"PCT_CHANGE_20\"]]",
   "id": "3e2141001e5528c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder_name = 'bdataaug'\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "for i in range(len(tdf)):\n",
    "    tdf[i].to_csv(f'{folder_name}/train_{i}.csv', index=False)\n",
    "    vdf[i].to_csv(f'{folder_name}/valid_{i}_pred.csv', index=False)"
   ],
   "id": "8df26f6307e27824",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "valid.to_csv(f'{folder_name}/valid_pred_all.csv', index=True)",
   "id": "5b3323bf2e762796",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
